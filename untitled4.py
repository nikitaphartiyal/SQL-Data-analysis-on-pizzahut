# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q3j4d9uFPmR9MMqfeRo4o_lVz6er8Nnu

# This is Pizza Sales Analysis

Having 4 dataset
"""



import pandas as pd
import time
import logging
from sqlalchemy import create_engine
import warnings

warnings.filterwarnings('ignore')

# --- Setup logger ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Remove old handlers if they exist
if logger.hasHandlers():
    logger.handlers.clear()

file_handler = logging.FileHandler("log_file.log", mode="w")
formatter = logging.Formatter(" %(asctime)s - %(levelname)s - %(message)s",datefmt='%Y-%m-%d %H:%M:%S')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

logger.info("--- Logging started. ---")

# --- Create database engine ---
engine = create_engine("sqlite:///pizza.db")
logger.info(f"Successfully created the engine: {engine}")

# --- Read CSV files ---
files = {
    "order_details": "/content/order_details.csv",
    "orders": "/content/orders.csv",
    "pizzas_type": "/content/pizza_types.csv",
    "pizzas": "/content/pizzas.csv"
}

dataframes = {}

for name, path in files.items():
    try:
        if name == "pizzas_type":
            df = pd.read_csv(path, encoding='latin')
        else:
            df = pd.read_csv(path)
        dataframes[name] = df
        logger.info(f"Loaded '{name}' with shape {df.shape}.")
        print(f"{name} : {df.shape}")
    except FileNotFoundError:
        logger.error(f"File '{path}' not found.")
    except Exception as e:
        logger.error(f"Error loading '{name}': {e}")

# --- Insert DataFrames into database ---
chunksize = 10000

for table_name, df in dataframes.items():
    logger.info(f"Starting to insert DataFrame into table '{table_name}'.")
    print(50 * "-")  # Separator line before starting each table insertion
    try:
        start_time = time.time()
        i = 0
        for start in range(0, len(df), chunksize):
            chunk = df.iloc[start:start+chunksize]
            chunk.to_sql(table_name, con=engine, if_exists="append", index=False)
            i += 1
            logger.info(f"Inserted chunk {i} with {chunk.shape[0]} rows into '{table_name}' table.")

        end_time = time.time()
        total_time = end_time - start_time
        print(f"Total time taken to insert '{table_name}': {total_time:.2f} seconds")
        logger.info(f"âœ… Finished inserting into '{table_name}' table in {total_time:.2f} seconds.")

    except Exception as e:
        logger.error(f"An error occurred while inserting into '{table_name}': {e}")

    print(50 * "-")  # Separator line after finishing each table insertion

logger.info("âœ… All DataFrames inserted successfully!")

# --- Ensure all logs are written ---
for handler in logger.handlers:
    handler.flush()

""" Print the log file contents ---
print("\n=== Log File Contents ===")
with open("log_file.log", "r") as file:
    print(file.read())"""

for data , df in dataframes.items():
  print(data,end=" ")
  print(" ")
  print(df.head())

"""ðŸ“Š Data Overview â€“ What I see
1. Order Details (order_details)

Tracks each item in an order.

Shows which pizzas are ordered and in what quantity.

âœ… Useful to understand customer preferences and popular pizzas.
"""

sql=pd.read_sql(""" select pizza_type_id,
 sum(quantity) as totalquantity from order_details
 join
 pizzas
 on order_details.pizza_id=pizzas.pizza_id
 group by pizza_type_id
 order by totalquantity DESC limit 10
""", engine)

sql

"""THIS INDICATES THAT OUR TOP 10 BEST PIZZAS ARE :

1.Lclassic_dlx

2	bbq_ckn	2432

3	hawaiian	2422

4	pepperoni	2418

5	thai_ckn	2371

6	cali_ckn	2370

7	sicilian	1938

8	spicy_ital	1924

9	southw_ckn	1917

10	big_meat	1914

2. Orders (orders)

Contains order timestamps.

 Great to analyze peak hours, busiest days, and patterns in customer behavior.
"""

sql = pd.read_sql("""
    SELECT strftime('%w', date) AS day_of_week,
           COUNT(*) AS total_order
    FROM orders
    GROUP BY day_of_week
    ORDER BY total_order DESC
""", engine)
sql2 = pd.read_sql("""
    SELECT strftime('%H', time) AS time_of_day,
           COUNT(*) AS total_order
    FROM orders
    GROUP BY time_of_day
    ORDER BY total_order DESC
""", engine)
day_mapping = {
    '0': 'Sunday',
    '1': 'Monday',
    '2': 'Tuesday',
    '3': 'Wednesday',
    '4': 'Thursday',
    '5': 'Friday',
    '6': 'Saturday'
}

# Apply the mapping
sql['day_of_week'] = sql['day_of_week'].map(day_mapping)
sql3 = pd.read_sql("""
    SELECT date,
           COUNT(*) AS total_order
    FROM orders
    GROUP BY date
    ORDER BY total_order DESC limit 10
""", engine)

print(" the bussiest day of the week are :")
print(sql)
print("the peak hours are : ")
print(sql2)
print("the busiest days are :")
print(sql3)

"""THIS SHOWS THAT THE BUSIEST DAY IN A WEEK WAS FRIDAY , BUSIEST HOUR WAS 12 PM AND BUSIEST DAY WAS 2015-NOV-27

3. Pricing Strategy

Prices vary by size. But are they aligned with customer preferences or competitors?

Condition: Analyze how pricing impacts order frequency and customer satisfaction.

Explore bundling options or loyalty discounts.
"""

sql=pd.read_sql("""
select size , sum(quantity) as total_quantity , avg(price) as avg_price from order_details join pizzas
on order_details.pizza_id=pizzas.pizza_id
group by size
order by total_quantity Desc""", engine)

sql

"""Large pizzas (L) are by far the most popular â€” nearly 19,000 orders.

Customers likely see them as a good balance between quantity and price.

Medium pizzas (M) are also ordered frequently â†’ customers value affordability.

Small pizzas (S) have slightly lower but still significant orders â†’ perhaps for individuals or light meals.

Extra-large (XL) and XXL pizzas are barely ordered â†’ they might be too expensive or too much for typical customers.

. Customer Behavior & Peak Hours

Orders have date and time stamps.

Problem: If I donâ€™t know peak hours or slow times, I cannot staff properly or plan marketing pushes.

Example: If orders spike around lunch but taper off later, I might introduce meal deals at off-peak hours.
"""

sql = pd.read_sql("""
    SELECT strftime('%w', date) AS day_of_week,
           COUNT(*) AS total_order
    FROM orders
    GROUP BY day_of_week
    ORDER BY total_order DESC
""", engine)
sql2 = pd.read_sql("""
    SELECT strftime('%H', time) AS time_of_day,
           COUNT(*) AS total_order
    FROM orders
    GROUP BY time_of_day
    ORDER BY total_order DESC limit 6
""", engine)
day_mapping = {
    '0': 'Sunday',
    '1': 'Monday',
    '2': 'Tuesday',
    '3': 'Wednesday',
    '4': 'Thursday',
    '5': 'Friday',
    '6': 'Saturday'
}
print("the bussiest day of the week are :-")
print(sql)
print('the peak hour are:-')
print(sql2)

logger.info("completed 4 tasks")

with open("log_file.log","r") as file :
  print(file.read())

"""âœ… 5. Menu Customization and Trends

Ingredient data helps understand dietary trends (e.g. vegan options, low-carb, etc.).

Condition: I can innovate or adjust recipes based on customer preferences.
"""

sql = pd.read_sql("""
   select  ingredients from pizzas_type where pizza_type_id="classic_dlx"
""", engine)
sql

sql = pd.read_sql("""
    SELECT pt.category, SUM(od.quantity) AS total_orders
    FROM order_details od
    JOIN pizzas p ON od.pizza_id = p.pizza_id
    JOIN pizzas_type pt ON p.pizza_type_id = pt.pizza_type_id
    GROUP BY pt.category
    ORDER BY total_orders DESC
""", engine)

print(sql)

sql = pd.read_sql("""
    SELECT pt.name,
           SUM(od.quantity) AS total_quantity,
           CASE
                WHEN pt.ingredients LIKE '%Chicken%'
                  OR pt.ingredients LIKE '%Bacon%'
                  OR pt.ingredients LIKE '%Ham%'
                  OR pt.ingredients LIKE '%Salmon%'
                  OR pt.ingredients LIKE '%Beef%'
                THEN 'Non-Vegetarian'
                ELSE 'Vegetarian'
           END AS diet_type
    FROM order_details od
    JOIN pizzas p
        ON od.pizza_id = p.pizza_id
    JOIN pizzas_type pt
        ON p.pizza_type_id = pt.pizza_type_id
    GROUP BY pt.name, diet_type
    ORDER BY total_quantity DESC
""", engine)

print(sql)

sql = pd.read_sql("""
    SELECT
        SUM(od.quantity) AS total_quantity,
        SUM(od.quantity * p.price) AS total_revenue,
        SUM(p.price * 60)/100 AS estimated_cost,
        SUM(od.quantity * p.price) - SUM(p.price * 60)/100 AS profit,
        (SUM(od.quantity * p.price) - SUM(p.price * 60)/100) / SUM(od.quantity * p.price) * 100 AS margin_percent,
        CASE
            WHEN pt.ingredients LIKE '%Chicken%'
              OR pt.ingredients LIKE '%Bacon%'
              OR pt.ingredients LIKE '%Ham%'
              OR pt.ingredients LIKE '%Salmon%'
              OR pt.ingredients LIKE '%Beef%'
            THEN 'Non-Vegetarian'
            ELSE 'Vegetarian'
        END AS diet_type
    FROM order_details od
    JOIN pizzas p
        ON od.pizza_id = p.pizza_id
    JOIN pizzas_type pt
        ON p.pizza_type_id = pt.pizza_type_id
    GROUP BY diet_type
    ORDER BY total_quantity DESC
""", engine)

print(sql)



"""âœ… 6. Profitability Monitoring

By combining orders and pricing data, I can track revenue and cost for each pizza.

Problem: Some pizzas may have high ingredient costs but low margins, which can reduce profitability.

Action: Identify high-cost, low-margin pizzas to control waste and adjust pricing strategies.
"""

sql = pd.read_sql("""
    SELECT pt.name,
           SUM(od.quantity) AS total_quantity,
           p.price AS price_per_unit,
           SUM(od.quantity * p.price) AS total_revenue
    FROM order_details od
    JOIN pizzas p
        ON od.pizza_id = p.pizza_id
    JOIN pizzas_type pt
        ON p.pizza_type_id = pt.pizza_type_id
    GROUP BY pt.name, p.price
    ORDER BY total_revenue DESC
""", engine)

print(sql)

"""you can assume a cost percentage based on typical food industry practices, e.g.:

Assume the cost of ingredients is 60% of the price â†’ cost = price Ã— 0.6

Or define custom cost ratios by pizza category.
"""

# Assume 60% cost for simplicity
sql['estimated_cost'] = sql['price_per_unit'] * 0.6
sql['profit'] = sql['total_revenue'] - sql['estimated_cost'] * sql['total_quantity']
sql['margin_percent'] = (sql['profit'] / sql['total_revenue']) * 100

print(sql)

for i,row in sql.iterrows():
    if sql["margin_percent"].iloc[i] < 40:
        print(i,row["name"],"--loss")
    else:
        print(i,row["name"], "--profit")

sql = pd.read_sql("""
    SELECT
           p.size,
           SUM(od.quantity) AS total_quantity,
           p.price AS price_per_unit,
           SUM(od.quantity * p.price) AS total_revenue
    FROM order_details od
    JOIN pizzas p
        ON od.pizza_id = p.pizza_id
    JOIN pizzas_type pt
        ON p.pizza_type_id = pt.pizza_type_id
    GROUP BY p.size
    ORDER BY total_revenue DESC
""", engine)

print(sql)

# Assume 60% cost for simplicity
sql['estimated_cost'] = sql['price_per_unit'] * 0.6
sql['profit'] = sql['total_revenue'] - sql['estimated_cost'] * sql['total_quantity']
sql['margin_percent'] = (sql['profit'] / sql['total_revenue']) * 100

print(sql)

